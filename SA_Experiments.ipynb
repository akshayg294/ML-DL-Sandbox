{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32f20a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import datetime\n",
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact\n",
    "from IPython.display import display\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from google.cloud import bigquery\n",
    "from google.oauth2 import service_account\n",
    "import seaborn as sns\n",
    "import swifter\n",
    "\n",
    "sns.set(style=\"whitegrid\")\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "import json\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "################ MODEL RELATED\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# from keras.utils import np_utils\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, f1_score\n",
    "\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import bigquery_storage\n",
    "from google.oauth2 import service_account\n",
    "import datetime\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from Source.inception import InceptionBlock\n",
    "\n",
    "\n",
    "class Flatten(nn.Module):\n",
    "    def __init__(self, out_features):\n",
    "        super(Flatten, self).__init__()\n",
    "        self.output_dim = out_features\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, self.output_dim)\n",
    "\n",
    "\n",
    "class Reshape(nn.Module):\n",
    "    def __init__(self, out_shape):\n",
    "        super(Reshape, self).__init__()\n",
    "        self.out_shape = out_shape\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x.view(-1, *self.out_shape)\n",
    "\n",
    "\n",
    "def getdata_from_logger(dirpath, query, readfromlocal=True):\n",
    "    if readfromlocal:\n",
    "        logger_data = pd.read_pickle(dirpath + '\\\\Data\\\\logger_data.pkl')\n",
    "        return logger_data\n",
    "\n",
    "    input('Get Data from Logger?')\n",
    "    credentials = service_account.Credentials.from_service_account_file(dirpath + '\\\\Source\\\\Config\\\\bigqueryauth.json')\n",
    "    project_id = 'solar-222307'\n",
    "    client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "    # bqstorage = bigquery_storage.BigQueryReadClient(credentials=credentials)\n",
    "\n",
    "    query_job = client.query(query)\n",
    "    result = query_job.result()\n",
    "    logger_data = result.to_dataframe()\n",
    "    logger_data.to_pickle(dirpath + '\\\\Data\\\\logger_data.pkl')\n",
    "    return logger_data\n",
    "\n",
    "\n",
    "def getdata(dirpath, download_data=False, read_csv=False):\n",
    "    print(\"Downloading/ getting data\")\n",
    "    # os.chdir(r'C:\\Users\\Akshay Gupta\\Documents\\Projects\\Homescape\\Raycon\\Raycon Data')\n",
    "    racon_pickle_path = dirpath + '\\\\Data\\\\raycon_data.pkl'\n",
    "\n",
    "    if read_csv is True:\n",
    "        raycon_data = pd.read_csv(dirpath + '\\\\Data\\\\bq_050821_1400.csv')\n",
    "        raycon_data['logged_on_utc'] = pd.to_datetime(raycon_data['logged_on_utc'])\n",
    "        raycon_data = raycon_data.reset_index()\n",
    "        return raycon_data\n",
    "\n",
    "    if download_data is False:\n",
    "        raycon_data = pd.read_pickle(racon_pickle_path)\n",
    "        raycon_data = raycon_data.reset_index()\n",
    "        return raycon_data\n",
    "\n",
    "    credentials = service_account.Credentials.from_service_account_file(dirpath + '\\\\Source\\\\Config\\\\bigqueryauth.json')\n",
    "    project_id = 'solar-222307'\n",
    "    client = bigquery.Client(credentials=credentials, project=project_id)\n",
    "    bqstorage = bigquery_storage.BigQueryReadClient(credentials=credentials)\n",
    "    try:\n",
    "        raycon_data = pd.read_pickle(racon_pickle_path)\n",
    "        raycon_data['logged_on_utc'] = pd.to_datetime(raycon_data['logged_on_utc'])\n",
    "        last_timestamp = raycon_data.sort_values('logged_on_utc')['logged_on_utc'].iloc[-1]\n",
    "        query_job = client.query('select * from dev_loggers.raycon where logged_on_utc>\"{}\"'.format(last_timestamp))\n",
    "        results = query_job.result().to_dataframe()\n",
    "        results = results.dropna(subset=['logged_on_utc'])\n",
    "        raycon_data['logged_on_utc'] = pd.to_datetime(raycon_data['logged_on_utc'])\n",
    "        raycon_data = raycon_data.append(results)\n",
    "    except FileNotFoundError:\n",
    "        last_timestamp = '2011-10-10'\n",
    "        query_job = client.query('select * from dev_loggers.raycon where logged_on_utc>\"{}\"'.format(last_timestamp))\n",
    "        results = query_job.result().to_dataframe(bqstorage_client=bqstorage,\n",
    "                                                  progress_bar_type='tqdm_notebook')\n",
    "        results = results.dropna(subset=['logged_on_utc'])\n",
    "        raycon_data = results\n",
    "    raycon_data.to_pickle('raycon_data.pkl')\n",
    "    raycon_data = raycon_data.reset_index()\n",
    "\n",
    "    return raycon_data\n",
    "\n",
    "\n",
    "def getmetadata(pivot_data, device_map):\n",
    "    device_map1 = device_map[['tuya_id', 'name']].set_index('tuya_id').to_dict()['name']\n",
    "    device_map2 = device_map[['tuya_id', 'mean_power_consumption']].set_index('tuya_id').to_dict()[\n",
    "        'mean_power_consumption']\n",
    "    device_map3 = device_map[['tuya_id', 'consumption_category']].set_index('tuya_id').to_dict()['consumption_category']\n",
    "    device_map4 = device_map[['tuya_id', 'type']].set_index('tuya_id').to_dict()['type']\n",
    "    pivot_data['name'] = pivot_data['device_id'].map(device_map1)\n",
    "    pivot_data['device_mean_consumption'] = pivot_data['device_id'].map(device_map2)\n",
    "    pivot_data['consumption_category'] = pivot_data['device_id'].map(device_map3)\n",
    "    pivot_data['type'] = pivot_data['device_id'].map(device_map4)\n",
    "    return pivot_data\n",
    "\n",
    "\n",
    "def timestamptodatetime(timestamp, converttosecs=False, istbool=False):\n",
    "    rawtimestamp = datetime.datetime.fromtimestamp(timestamp / 1000)\n",
    "    rawtimestamp = rawtimestamp.replace(tzinfo=None)\n",
    "    if istbool:\n",
    "        rawtimestamp = rawtimestamp + datetime.timedelta(hours=5, minutes=30)\n",
    "    return rawtimestamp\n",
    "\n",
    "def timechangef1(timestamp):\n",
    "    return datetime.datetime.fromtimestamp(timestamp / 1000) + datetime.timedelta(hours=5.5)\n",
    "\n",
    "\n",
    "def getfeatures(stdate, enddate, data, historical_data):\n",
    "    ### When calling from loop\n",
    "    print('start: ', datetime.datetime.now())\n",
    "    if 'other' in data.columns:\n",
    "        temp = pd.DataFrame(json.loads(historical_data))\n",
    "        temp['logged_time_local'] = [datetime.datetime.fromtimestamp(timestamp / 1000) + datetime.timedelta(hours=5.5)\n",
    "                                     for timestamp in temp['logged_on_utc']]\n",
    "        temp['mains_power'] = (temp['active_power_P1'] + temp['active_power_P2'] + temp['active_power_P3']) / 1000\n",
    "        if len(temp) > 0:\n",
    "            df = temp[['logged_time_local', 'mains_power']]\n",
    "            df = temp.append(data[['logged_time_local', 'mains_power']])\n",
    "        else:\n",
    "            df = sample_data[['logged_time_local', 'mains_power']]\n",
    "        n = len(temp)\n",
    "\n",
    "    else:\n",
    "        print('In else statement: ', datetime.datetime.now())\n",
    "        sample_data = data[(data['logged_on_utc'] >= pd.to_datetime(stdate) - datetime.timedelta(hours=5.5)) & (\n",
    "                data['logged_on_utc'] <= pd.to_datetime(enddate) - datetime.timedelta(hours=5.5))].sort_values(\n",
    "            'logged_on_utc')\n",
    "        df = pd.DataFrame(columns=sample_data.columns)\n",
    "        df = df.append(pd.DataFrame(json.loads(historical_data)))\n",
    "        n = len(df)\n",
    "        #### Time change in pipeline\n",
    "#         df['logged_time_local'] = [datetime.datetime.fromtimestamp(timestamp / 1000) + datetime.timedelta(hours=5.5) for\n",
    "#                                    timestamp in df['logged_on_utc']]\n",
    "        df['logged_time_local'] = df.swifter.apply(lambda row: timechangef1(row.logged_on_utc), axis=1)\n",
    "        sample_data['logged_time_local'] = df.swifter.apply(lambda row: timechangef1(row.logged_on_utc), axis=1)\n",
    "        sample_data = sample_data.sort_values('logged_time_local').drop_duplicates('logged_time_local').set_index(\n",
    "            'logged_time_local').reset_index()\n",
    "        df = df.append(sample_data)\n",
    "        df['mains_power'] = (df['active_power_P1'] + df['active_power_P2'] + df['active_power_P3']) / 1000\n",
    "    #         print(df)\n",
    "    frequency = 20\n",
    "    mean_step = 30\n",
    "    factor = 10\n",
    "    # sample_data=df\n",
    "    # Processing\n",
    "    df['before_mean'] = df['mains_power'].rolling(mean_step).mean()\n",
    "    df['before_max_10'] = df['mains_power'].abs().rolling(mean_step * factor).max()\n",
    "    df['before_mean_10'] = df['mains_power'].abs().rolling(mean_step * factor).mean()\n",
    "    df['after_mean'] = 0\n",
    "    df['after_mean_10'] = 0\n",
    "    df['after_max_10'] = 0\n",
    "    df['per_change'] = 0\n",
    "    df['time_spent'] = 0\n",
    "\n",
    "\n",
    "    # Features\n",
    "    print('Creating Features: ', datetime.datetime.now())\n",
    "    per_change = []\n",
    "    after_mean = []\n",
    "    after_mean_10 = []\n",
    "    after_max = []\n",
    "\n",
    "    for i in range(mean_step, len(df) - mean_step):\n",
    "        change = 100 * (df['before_mean'].iloc[i + mean_step] - df['before_mean'].iloc[i - 1]) / df['before_mean'].iloc[\n",
    "            i + mean_step]\n",
    "        per_change.append(change)\n",
    "        after_mean.append(df['before_mean'].iloc[i + mean_step])\n",
    "\n",
    "    for i in range(mean_step * factor, len(df) - mean_step * factor - 3):\n",
    "        after_mean_10.append(df['before_mean_10'].iloc[i + 3 + mean_step * factor])\n",
    "        after_max.append(df['before_max_10'].iloc[i + 3 + mean_step * factor])\n",
    "\n",
    "    df['per_change'].iloc[mean_step:-mean_step] = per_change\n",
    "    df['after_mean'].iloc[mean_step:-mean_step] = after_mean\n",
    "    df['after_mean_10'].iloc[mean_step * factor:-mean_step * factor - 3] = after_mean_10\n",
    "    df['after_max_10'].iloc[mean_step * factor:-mean_step * factor - 3] = after_max\n",
    "    df['avg_diff'] = df['after_mean'] - df['before_mean']\n",
    "    df['avg_diff'] = df['after_mean'] - df['before_mean']\n",
    "\n",
    "    # event logic\n",
    "    print('event logic: ', datetime.datetime.now())\n",
    "    df['events'] = 0\n",
    "    df.loc[(abs(df['avg_diff']) > .015) & (df['mains_power'] < .10), 'events'] = 1\n",
    "    df.loc[(abs(df['per_change']) > 10) & (df['mains_power'] > .10), 'events'] = 1\n",
    "    df = df\n",
    "    df['event_type'] = 0\n",
    "\n",
    "    # event smoothening\n",
    "    print('event smoothening: ', datetime.datetime.now())\n",
    "    df['event_smoothening'] = df['events'].rolling(int(factor / 2)).mean()\n",
    "    df['events'] = [1 if i > .5 else 0 for i in df['event_smoothening']]\n",
    "\n",
    "    #### transition start=1, transition= 2, transition end=3, steady=0\n",
    "    df.loc[df['events'] == True, 'event_type'] = 2\n",
    "    df.loc[df['events'] == False, 'event_type'] = 0\n",
    "\n",
    "    #### map transition states\n",
    "    df['event_effect'] = 0\n",
    "    prev_state = 0\n",
    "    event_mean_before = 0\n",
    "    for i in range(1, len(df)):\n",
    "        if df['events'].iloc[i] == 0:\n",
    "            if prev_state == 1:\n",
    "                df['event_type'].iloc[i - 1] = 3\n",
    "            prev_state = 0\n",
    "        else:\n",
    "            if prev_state == 0:\n",
    "                df['event_type'].iloc[i] = 1\n",
    "            prev_state = 1\n",
    "\n",
    "    #### Observable events for on/off activity\n",
    "    print('observable events: ', datetime.datetime.now())\n",
    "    df['observable_event'] = 0\n",
    "    df['event_effect'] = 0\n",
    "    for i in range(len(df)):\n",
    "        if df['event_type'].iloc[i] == 1:\n",
    "            after = 0\n",
    "            j = i + 5 * frequency\n",
    "            for j in range(i + 5 * frequency, min(i + 5 * frequency + mean_step * factor, len(df) - 1)):\n",
    "                if (df['event_type'].iloc[j] != 1):\n",
    "                    after = after + df['mains_power'].iloc[j]\n",
    "                else:\n",
    "                    break\n",
    "            after = after / (j - (i + 5 * frequency - 1))\n",
    "            before = 0\n",
    "            k = i - 3 * frequency\n",
    "            for k in range(i - 3 * frequency, max(i - 3 * frequency - mean_step * factor, 0), -1):\n",
    "                if (df['event_type'].iloc[k] != 1):\n",
    "                    before = before + df['mains_power'].iloc[k]\n",
    "                else:\n",
    "                    break\n",
    "            before = before / (i - (k + 3 * frequency - 1))\n",
    "            df['event_effect'].iloc[i] = after - before\n",
    "\n",
    "    df.loc[(abs(df['event_effect']) > .010), 'observable_event'] = 1\n",
    "    df.loc[(df['event_effect'] < 0) & (df['observable_event'] == 1), 'observable_event'] = 2\n",
    "    #     print(df)\n",
    "    #     print(df.iloc[n:,:])\n",
    "\n",
    "    df['model_data'] = pd.concat([df.mains_power.shift(i) for i in range(10)], 1).fillna(0).values.tolist()\n",
    "    return df.iloc[n:, :]\n",
    "\n",
    "\n",
    "# def classify_appliance(appliances,power,device_map):\n",
    "#     if appliances=='all':\n",
    "#         return device_map['name'].iloc[(device_map['mean_power_consumption']-power).abs().argsort()[:1]].values[0]\n",
    "#     else:\n",
    "#         if len(device_map.loc[device_map['name'].isin(appliances)])==0:\n",
    "#             return 0\n",
    "#         else:\n",
    "#             return device_map.loc[device_map['name'].isin(appliances),'name'].iloc[(device_map.loc[device_map['name'].isin(appliances), 'mean_power_consumption']-abs(power)).abs().argsort()[:1]].values[0]\n",
    "\n",
    "def classify_appliance(appliances, power, device_map, category=True):\n",
    "    #     if global_equipment.training_available:\n",
    "    #         model.load()\n",
    "    #         model.predict(power)\n",
    "\n",
    "    #     else:\n",
    "    if appliances == 'all':\n",
    "        return device_map['name'].iloc[(device_map['mean_power_consumption'] - power).abs().argsort()[:1]].values[0]\n",
    "    else:\n",
    "        if len(device_map.loc[\n",
    "                   (device_map['name'].isin(appliances)) & (device_map['consumption_category'] == category)]) == 0:\n",
    "            return 0\n",
    "        else:\n",
    "            return device_map.loc[\n",
    "                (device_map['name'].isin(appliances)) & (device_map['consumption_category'] == category), 'name'].iloc[\n",
    "                (device_map.loc[(device_map['name'].isin(appliances)) & (device_map['consumption_category'] == category)\n",
    "                , 'mean_power_consumption'] - abs(power)).abs().argsort()[:1]].values[0]\n",
    "\n",
    "\n",
    "# def estimated_usage(std,endd,appliance,device_map):\n",
    "#     return device_map.loc[device_map['name']==appliance, 'mean_power_consumption']*(endd-std).seconds/3600\n",
    "\n",
    "def getoutput(stdate, enddate, temp_data, device_map, historical_json):\n",
    "    event_df = pd.DataFrame(\n",
    "        columns=['start_on_local', 'end_on_local', 'avg_mains_power', 'equipment_name', 'status', 'energy_consumption',\n",
    "                 'event_on_local', 'event_off_local'])\n",
    "    ind = 1\n",
    "    prev_avg_mains_power = .2\n",
    "    active_names = {}\n",
    "    active_names['other'] = stdate\n",
    "    #     main_temp=pd.DataFrame()\n",
    "    #     appliance_list=[]\n",
    "    #     event_df=pd.DataFrame(columns=['start_on_local','end_on_local','avg_mains_power','name','status','energy_consumption','event_on_local','event_off_local'])\n",
    "    main_temp = pd.DataFrame()\n",
    "    appliance_list = []\n",
    "    for start, end in zip(pd.date_range(stdate, enddate, freq='5min')[:-1],\n",
    "                          pd.date_range(stdate, enddate, freq='5min')[1:]):\n",
    "        print(start)\n",
    "        event_df_temp = pd.DataFrame(\n",
    "            columns=['start_on_local', 'end_on_local', 'avg_mains_power', 'name', 'status', 'energy_consumption',\n",
    "                     'event_on_local', 'event_off_local'])\n",
    "        temp = temp_data.set_index('logged_time_local')\n",
    "        temp = temp[(temp.index <= end) & (temp.index >= start)]\n",
    "        event_df_temp.loc[ind] = [start, end, None, 'all', 'NA', temp['mains_power'].sum() / 3600, None, None]\n",
    "        temp['active_appliances'] = None\n",
    "        for name in active_names.keys():\n",
    "            ind = ind + 1\n",
    "            event_df_temp.loc[ind, 'name'] = name\n",
    "            event_df_temp.loc[event_df_temp['name'] == name, 'event_on_local'] = str(start)\n",
    "            event_df_temp.loc[event_df_temp['name'] == name, 'status'] = 'active'\n",
    "\n",
    "        event_df_temp.loc[event_df_temp['name'] == 'other'] = [start, end, prev_avg_mains_power, 'other', 'NA', 0,\n",
    "                                                               str(start), str(end)]\n",
    "        for i in range(len(temp)):\n",
    "            temp['active_appliances'].iloc[i] = list(active_names)\n",
    "            if temp['observable_event'].iloc[i] == 1:\n",
    "\n",
    "                name = classify_appliance('all', abs(temp['event_effect'].iloc[i]), device_map)\n",
    "                if name in event_df_temp['name'].unique():\n",
    "                    if name in active_names.keys():\n",
    "                        continue\n",
    "                    else:\n",
    "                        active_names[name] = str(temp.index[i])\n",
    "                        event_df_temp.loc[event_df_temp['name'] == name, 'status'] = 'active'\n",
    "                        event_df_temp.loc[event_df_temp['name'] == name, 'event_on_local'] = str(\n",
    "                            event_df_temp.loc[event_df_temp['name'] == name, 'event_on_local'].values[0]) + ' ' + str(\n",
    "                            temp.index[i])\n",
    "                else:\n",
    "                    ind = ind + 1\n",
    "                    event_df_temp.loc[ind, 'event_on_local'] = str(temp.index[i])\n",
    "                    event_df_temp.loc[ind, 'name'] = name\n",
    "                    event_df_temp.loc[ind, 'status'] = 'active'\n",
    "                    active_names[name] = str(temp.index[i])\n",
    "\n",
    "            elif temp['observable_event'].iloc[i] == 2:\n",
    "                category = \\\n",
    "                    ['high' if v > 1 else 'low' if v <= .01 else 'medium' for v in [abs(temp['event_effect'].iloc[i])]][\n",
    "                        0]\n",
    "                name = classify_appliance(active_names.keys(), abs(temp['event_effect'].iloc[i]), device_map, category)\n",
    "                if name == 0:\n",
    "                    continue\n",
    "                if len(event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'].dropna()) == 0:\n",
    "                    event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'] = str(temp.index[i])\n",
    "                else:\n",
    "                    event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'] = str(\n",
    "                        event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'].values[0]) + ',' + str(\n",
    "                        temp.index[i])\n",
    "                event_df_temp.loc[event_df_temp['name'] == name, 'status'] = 'off'\n",
    "                del active_names[name]\n",
    "            else:\n",
    "                continue\n",
    "\n",
    "        for name in active_names.keys():\n",
    "            if name == 'other':\n",
    "                continue\n",
    "            if len(event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'].dropna()) == 0:\n",
    "                event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'] = str(temp.index[i])\n",
    "            else:\n",
    "                event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'] = str(\n",
    "                    event_df_temp.loc[event_df_temp['name'] == name, 'event_off_local'].values[0]) + ',' + str(\n",
    "                    temp.index[i])\n",
    "        event_df_temp['start_on_local'] = start\n",
    "        event_df_temp['end_on_local'] = end\n",
    "\n",
    "        for iterator in range(3):\n",
    "            if iterator == 0:\n",
    "                per_second_energy, energy_dict = energy_estimation(temp, prev_avg_mains_power)\n",
    "            else:\n",
    "                per_second_energy, energy_dict = energy_estimation(sample_df, prev_avg_mains_power)\n",
    "            #             print(temp)\n",
    "            per_second_energy['mains_power'] = per_second_energy['other']\n",
    "\n",
    "            for equip in list(energy_dict):\n",
    "                if equip == 'other':\n",
    "                    continue\n",
    "                else:\n",
    "                    event_df_temp.loc[event_df_temp['name'] == equip, 'energy_consumption'] = event_df_temp.loc[\n",
    "                                                                                                  event_df_temp[\n",
    "                                                                                                      'name'] == equip, 'energy_consumption'].fillna(\n",
    "                        0) + energy_dict[equip] / 3600\n",
    "            #             print(per_second_energy)\n",
    "            sample_df = getfeatures(stdate, enddate, per_second_energy, historical_json)\n",
    "            #             print(sample_df)\n",
    "            sample_df = sample_df.set_index('logged_time_local')\n",
    "            sample_df['active_appliances'] = temp['active_appliances']\n",
    "\n",
    "        event_df_temp.loc[event_df_temp['name'] == 'other', 'energy_consumption'] = energy_dict['other'] / 3600\n",
    "        prev_avg_mains_power = energy_dict['other'] / 3600\n",
    "        event_df = event_df.append(event_df_temp)\n",
    "        main_temp = main_temp.append(temp)\n",
    "\n",
    "    device_map1 = device_map[['name', 'tuya_id']].set_index('name').to_dict()['tuya_id']\n",
    "    device_map2 = device_map[['name', 'room']].set_index('name').to_dict()['room']\n",
    "    device_map3 = device_map[['name', 'consumption_category']].set_index('name').to_dict()['consumption_category']\n",
    "    device_map4 = device_map[['name', 'phase']].set_index('name').to_dict()['phase']\n",
    "    device_map5 = device_map[['name', 'type']].set_index('name').to_dict()['type']\n",
    "    event_df['tuya_id'] = event_df['name'].map(device_map1)\n",
    "    event_df['room'] = event_df['name'].map(device_map2)\n",
    "    event_df['consumption_category'] = event_df['name'].map(device_map3)\n",
    "    event_df['phase'] = event_df['name'].map(device_map4)\n",
    "    event_df['type'] = event_df['name'].map(device_map5)\n",
    "    event_df.loc[event_df['name'] == 'other', 'consumption_category'] = event_df.loc[\n",
    "        event_df['name'] != 'all', 'consumption_category'].fillna('other')\n",
    "    event_df.loc[event_df['name'] == 'other', 'type'] = 'other'\n",
    "    return main_temp, event_df\n",
    "\n",
    "\n",
    "def energy_estimation(temp, other_original):\n",
    "    #     temp=temp[['mains_power','active_appliances']]\n",
    "\n",
    "    # def energy_estimation(temp)\n",
    "    energy_dict = {l: 0 for l in list({x for l in list(temp.active_appliances) for x in l})}\n",
    "    prev_energy_dict = {}\n",
    "    #     other_original=0.088\n",
    "    energy_dict = {l: 0 for l in list({x for l in list(temp.active_appliances) for x in l})}\n",
    "    per_second_energy = []\n",
    "    ind = 0\n",
    "    df = pd.DataFrame(columns=energy_dict.keys())\n",
    "\n",
    "    for i in range(len(temp)):\n",
    "        prev_energy_dict['other'] = other_original\n",
    "\n",
    "        ### Distribution of Energy between Appliances\n",
    "        if len(prev_energy_dict) == len(temp.active_appliances.iloc[i]):\n",
    "            prev_energy_dict[list(prev_energy_dict.keys())[-1]] = temp.mains_power.iloc[i] - sum(\n",
    "                list(prev_energy_dict.values())[0:-1])\n",
    "\n",
    "        ### New Appliance is Active\n",
    "        elif len(prev_energy_dict) < len(temp.active_appliances.iloc[i]):\n",
    "            new_appliance = list((set(temp.active_appliances.iloc[i]) - set(prev_energy_dict)))[0]\n",
    "            prev_energy_dict[new_appliance] = temp.mains_power.iloc[i] - sum(prev_energy_dict.values())\n",
    "\n",
    "        ### One of the Appliances Deactives\n",
    "        else:\n",
    "            removed_appliance = list((set(prev_energy_dict) - set(temp.active_appliances.iloc[i])))[0]\n",
    "            del prev_energy_dict[removed_appliance]\n",
    "            prev_energy_dict[list(prev_energy_dict.keys())[-1]] = temp.mains_power.iloc[i] - sum(\n",
    "                list(prev_energy_dict.values())[0:-1])\n",
    "\n",
    "        ### Case When Calculated Equipment Usage > 1.5*Mean Consumption\n",
    "        excess = 0\n",
    "        negative_energy = []\n",
    "        for equipment in prev_energy_dict.keys():\n",
    "            if equipment == 'other':\n",
    "                continue\n",
    "            else:\n",
    "                equipment_energy = prev_energy_dict[equipment]\n",
    "                if equipment_energy > 0:\n",
    "                    prev_energy_dict[equipment] = min(equipment_energy, device_map.loc[\n",
    "                        device_map['name'] == equipment, 'mean_power_consumption'].values[0] * 1.5)\n",
    "                    excess = excess + equipment_energy - min(equipment_energy, device_map.loc[\n",
    "                        device_map['name'] == equipment, 'mean_power_consumption'].values[0] * 1.5)\n",
    "                else:\n",
    "                    negative_energy.append(equipment)\n",
    "\n",
    "        ### Remove Appliance if Calculated energy of appliance is negative\n",
    "        for negative_equipment in negative_energy:\n",
    "            del prev_energy_dict[negative_equipment]\n",
    "\n",
    "        ### Add Excessive Energy to other\n",
    "        other_original = prev_energy_dict['other']\n",
    "        prev_energy_dict['other'] = prev_energy_dict['other'] + excess\n",
    "\n",
    "        ### Check if Sum of all Appliance Energy> Original, if yes remove from original and subsequent appliances\n",
    "        for appliance_excess in list(prev_energy_dict):\n",
    "            if (sum(prev_energy_dict.values()) - temp.mains_power.iloc[i]) <= .015:\n",
    "                break\n",
    "            else:\n",
    "                if appliance_excess == 'other':\n",
    "                    prev_energy_dict[appliance_excess] = max(.015,\n",
    "                                                             temp.mains_power.iloc[i] - sum(prev_energy_dict.values()))\n",
    "                else:\n",
    "                    prev_energy_dict[appliance_excess] = max(0,\n",
    "                                                             temp.mains_power.iloc[i] - sum(prev_energy_dict.values()))\n",
    "\n",
    "        #     print(str(temp.index[i])+str(prev_energy_dict)+str(excess))\n",
    "        for j in prev_energy_dict.keys():\n",
    "            energy_dict[j] = energy_dict[j] + prev_energy_dict[j]\n",
    "        per_second_energy.append(str(prev_energy_dict))\n",
    "    per_second_energy = pd.DataFrame([eval(i) for i in per_second_energy])\n",
    "    per_second_energy['logged_time_local'] = temp.index\n",
    "\n",
    "    return per_second_energy, energy_dict\n",
    "\n",
    "\n",
    "def plot_around_observed_events(indice, data):\n",
    "    frequency = 20\n",
    "    timewindow = 5\n",
    "    startindice = max(0, indice - frequency * timewindow)\n",
    "    endindice = min(len(data) - 1, indice + frequency * timewindow)\n",
    "    data = (data[startindice:endindice][['mains_power']]).to_numpy()\n",
    "    plt.plot(data)\n",
    "    plt.show()\n",
    "    return\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d85d23d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path is : E:\\Code\\homescape_energy_disaggregation\n"
     ]
    }
   ],
   "source": [
    "from SA_FunctionsRaycon import *\n",
    "\n",
    "path = os.getcwd()\n",
    "print('Path is :', path)\n",
    "logger_query = 'SELECT logged_on_utc, device_id, property_id, active_power_P1, active_power_P2, active_power_P3 FROM ' \\\n",
    "               '`solar-222307.loggers.raycon` '\n",
    "\n",
    "logger_data = getdata_from_logger(path, logger_query, readfromlocal=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2525a0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "historical_json = logger_data.iloc[:60*20, :].to_json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddf79446",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_14244/4260556704.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mstdate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2021-07-20 00:00:00'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0menddate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'2021-07-31 00:00:00'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mgetfeatures\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstdate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0menddate\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhistorical_json\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mE:\\Code\\homescape_energy_disaggregation\\SA_FunctionsRaycon.py\u001b[0m in \u001b[0;36mgetfeatures\u001b[1;34m(stdate, enddate, data, historical_data)\u001b[0m\n\u001b[0;32m    200\u001b[0m     \u001b[0mper_change\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    201\u001b[0m     \u001b[0mafter_mean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 202\u001b[1;33m     \u001b[0mafter_mean_10\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    203\u001b[0m     \u001b[0mafter_max\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\homescape_energy_disaggregation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    929\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    930\u001b[0m             \u001b[0mmaybe_callable\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_if_callable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 931\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_getitem_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_callable\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    932\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    933\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_is_scalar_access\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mE:\\Code\\homescape_energy_disaggregation\\venv\\lib\\site-packages\\pandas\\core\\indexing.py\u001b[0m in \u001b[0;36m_getitem_axis\u001b[1;34m(self, key, axis)\u001b[0m\n\u001b[0;32m   1554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1555\u001b[0m         \u001b[1;31m# a list of integers\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1556\u001b[1;33m         \u001b[1;32melif\u001b[0m \u001b[0mis_list_like_indexer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1557\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_list_axis\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1558\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "stdate = '2021-07-20 00:00:00'\n",
    "enddate = '2021-07-31 00:00:00'\n",
    "getfeatures(stdate, enddate, logger_data, historical_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68e1f97f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
